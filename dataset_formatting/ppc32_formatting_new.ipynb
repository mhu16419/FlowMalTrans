{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob # folder operations\n",
    "import re # use regular expressions\n",
    "import logging \n",
    "# You perpahs need to restart the kernel in .ipynb to make the log module working normally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "opcode_set={'bltlr+', 'bdz', 'stwcx.', 'stbux', 'vsububm', 'divw', 'stvx', 'stbu', 'cmpw', 'vsl', \n",
    "              'bcl', 'bne-', 'ble-', 'stwux', 'sraw', 'lvsl', 'stb', 'bdnz', 'mtfsf', 'ble+', 'srwi.',\n",
    "              'cmplwi', 'subfe', 'beqlr+', 'bgt-', 'crset', 'subfc.', 'mulli', 'extsh', 'vncipher',\n",
    "              'beqlr-', 'rlwinm.', 'sthu', 'andc.', 'mflr', 'fmuls', 'vsrab', 'vspltisw', 'bnel',\n",
    "              'extrwi', 'cror', 'neg', 'addic', 'vpmsumd', 'addme', 'lhzu', 'mfspr', 'fabs', 'vaddubm',\n",
    "              'blelr', 'addis', 'nop', 'vspltisb', 'lwsync', 'bne+', 'fctiwz', 'addic.', 'vaddudm',\n",
    "              'vshasigmaw', 'andc', 'mtcrf', 'divwu', 'lis', 'srawi', 'lhzx', 'vsldoi', 'lwbrx', \n",
    "              'fcmpu', 'vspltb', 'mftb', 'fmadd', 'li', 'fmr', 'cmpwi', 'xxmrgld', 'mullw', 'add', \n",
    "              'stxvd2x', 'slw.', 'stbx', 'fsub', 'srawi.', 'lfdu', 'beq+', 'blt', 'not', 'vsel',\n",
    "              'clrlslwi', 'fadd', 'addi', 'fneg', 'stw', 'beq-', 'cntlzw.', 'lvx', 'crnot', 'and',\n",
    "              'extsb', 'fsubs', 'mcrf', 'lbz', 'frsp', 'lbzx', 'fadds', 'stwu', 'mffs', 'lwzux', \n",
    "              'isync', 'xor.', 'mulhwu', 'vnot', 'andis.', 'mtspr', 'subfe.', 'rlwimi.', 'cntlzw',\n",
    "              'fdivs', 'sthx', 'insrwi', 'node', 'andi.', 'bltlr', 'fdiv', 'rlwinm', 'bgelr', \n",
    "              'extsb.', 'mr', 'subf.', 'extlwi', 'bctr', 'bltlr-', 'srw', 'twlt', 'lbzux', \n",
    "              'lvsr', 'bgt+', 'vcipher', 'rotrwi', 'bge+', 'sth', 'xxmrghd', 'vperm', 'srdi', \n",
    "              'maddhdu', 'addze', 'mfctr', 'add.', 'stvewx', 'xoris', 'vmr', 'vadduwm', 'ori', \n",
    "              'addc', 'cmplw', 'lxvw4x', 'srwi', 'lha', 'addze.', 'srw.', 'rlwimi', 'bge-', 'subfc',\n",
    "              'beq', 'crclr', 'stfd', 'vmrgow', 'clrlwi', 'adde', 'fcfid', 'stfdu', 'not.', 'vand', \n",
    "              'bgtlr', 'bctrl', 'extrwi.', 'mtfsb0', 'vspltw', 'vslb', 'rotlw', 'oris', 'mr.', \n",
    "              'mtctr', 'stwx', 'eqv', 'maddld', 'beqlr', 'vsbox', 'lbzu', 'lwarx', 'xor', 'lfs',\n",
    "              'vrlw', 'vsrb', 'vor', 'vmrgew', 'clrrwi.', 'bgt', 'lxvd2x', 'bnelr', 'blt+', 'dcbf',\n",
    "              'vshasigmad', 'clrrwi', 'neg.', 'slwi.', 'subf', 'bge', 'subfze', 'lhax', 'xori', \n",
    "              'stxvw4x', 'bne', 'extsh.', 'lhau', 'slw', 'subfme', 'creqv', 'mtlr', 'vcipherlast',\n",
    "              'nand', 'bl', 'nor', 'lhaux', 'vncipherlast', 'lwz', 'slwi', 'bnelr+', 'mulhw', 'or',\n",
    "              'lwzx', 'blr', 'subfic', 'blelr+', 'mfcr', 'adde.', 'stvebx', 'lhz', 'lwzu',\n",
    "              'orc', 'orc.', 'stwbrx', 'fmul', 'and.', 'mtfsb1', 'crxor', 'blt-', 'stfs',\n",
    "              'ble', 'b', 'or.', 'fmsub', 'clrlwi.', 'mullw.', 'inslwi', 'lfd', 'rotlwi', 'vxor'}\n",
    "\n",
    "register_set={'r0','r1','r2','r3','r4','r5','r6','r7','r8','r9','r10',\n",
    "                  'r11','r12','r13','r14','r15','r16','r17','r18','r19','r20',\n",
    "                  'r21','r22','r23','r24','r25','r26','r27','r28','r29','r30','r31',\n",
    "                  'f0','f1','f2','f3','f4','f5','f6','f7','f8','f9','f10',\n",
    "                  'f11','f12','f13','f14','f15','f16','f17','f18','f19','f20',\n",
    "                  'f21','f22','f23','f24','f25','f26','f27','f28','f29','f30','f31',\n",
    "                  'cr7'\n",
    "                  }\n",
    "\n",
    "dummy_set={'TAG','VALUE','HEX','FUNC','STR','DWORD','JPT','ASC','UNK','TBYTE','QWORD','XMMWORD','LONG',\n",
    "               'DOUBLE','ARRAY','STRING','ARG','BYTE','SUB','WORD','LOCRET','DEF','OFF','FLT','DBL','LOC',\n",
    "               'STRU','GPGRT','GPG','YMMWORD','BUF','FILE','CALLBACK','CB','CURLSH','BUFFER','SCWTCH','VAR','STR',\n",
    "               'VAL','ALGN','SEG','SRC','INPUT','LOCAL','IMM','DUMMY','STD','ALLOC',\n",
    "               'ha'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_func_names(text, func_dict,lib):\n",
    "\n",
    "    if lib=='binutils':\n",
    "        func_set=func_dict['binutils']\n",
    "    elif lib=='coreutils':\n",
    "        func_set=func_dict['coreutils']\n",
    "    elif lib=='curl':\n",
    "        func_set=func_dict['curl']\n",
    "    elif lib=='diffutils':\n",
    "        func_set=func_dict['diffutils']\n",
    "    elif lib=='findutils':\n",
    "        func_set=func_dict['findutils']\n",
    "    elif lib=='libgpg':\n",
    "        func_set=func_dict['libgpg_error']    \n",
    "    elif lib=='openssl':\n",
    "        func_set=func_dict['openssl']\n",
    "    elif lib=='zlib':\n",
    "        func_set=func_dict['zlib']\n",
    "    else: \n",
    "        func_set=set()\n",
    "        print(f\"Warning, undetected library: {lib}\")                        \n",
    "\n",
    "    #pattern=r'\\b(' + '|'.join(func_set) + r')\\b'\n",
    "    pattern = r'\\b(' + '|'.join(re.escape(func) for func in func_set) + r')\\b(?=\\s*\\()'\n",
    "    # Split the text into lines\n",
    "    lines = text.split('\\n')\n",
    "    formatted_lines = []\n",
    "\n",
    "    # Iterate over each line\n",
    "    for line in lines:\n",
    "        # Split the line into the first word and the rest of the line\n",
    "        parts = line.split(' ', 1)\n",
    "        first_word = parts[0]\n",
    "        rest_of_line = parts[1] if len(parts) > 1 else ''\n",
    "        original_line=rest_of_line\n",
    "        # Replace occurrences of any function name in the rest of the line with '<FUNC>'\n",
    "        modified_rest_of_line = re.sub(r'_\\b(' + '|'.join(func_set) + r')\\b', ' <FUNC>', rest_of_line)\n",
    "        modified_rest_of_line = re.sub(pattern, ' <FUNC>', rest_of_line)\n",
    "        \n",
    "        #modified_rest_of_line = re.sub(underscore_pattern, ' <FUNC>', modified_rest_of_line)\n",
    "        #print(pattern)\n",
    "        # Concatenate the first word and the modified rest of the line\n",
    "        #if original_line != modified_rest_of_line:\n",
    "            #logging.info(f\"Formatting function: {original_line} -> {modified_rest_of_line}\")\n",
    "\n",
    "        formatted_line = first_word + (' ' + modified_rest_of_line if modified_rest_of_line else '')\n",
    "        formatted_lines.append(formatted_line)\n",
    "\n",
    "    # Join the formatted lines back into text\n",
    "    formatted_text = '\\n'.join(formatted_lines)\n",
    "    return formatted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_call_func(text):\n",
    "    \"\"\"\n",
    "    Converts lines starting with 'call' to '<FUNC_CALL>'.\n",
    "\n",
    "    Parameters:\n",
    "    - text (str): The input text in which to convert the lines.\n",
    "\n",
    "    Return\n",
    "    - str: The text with 'call' lines converted.The exact function is replaced with '<FUNC>'\n",
    "    \"\"\"\n",
    "    # Split the text into lines\n",
    "    lines = text.split('\\n')\n",
    "    # Convert lines starting with 'call'\n",
    "    converted_lines = ['bl <FUNC>' if line.lstrip().startswith('bl') else line for line in lines]\n",
    "    # Join the lines back into a single string\n",
    "    return '\\n'.join(converted_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_suffix_vars(text):\n",
    "    lines=text.split('\\n')\n",
    "    #opcode_pattern='|'.join(re.escape(opcode) for opcode in opcode_set)\n",
    "\n",
    "    aLarge_pattern=re.compile(r'\\s(a[A-Z][a-z0-9A-Z_\\.]+)\\_*\\d*')# match anything except for a lower or upper case letter\n",
    "    dword_pattern=re.compile(r'\\s(dword_[0-9a-zA-Z_\\.]+)')\n",
    "    jpt_pattern=re.compile(r'\\s(jpt_[0-9a-zA-Z_\\.]+)')\n",
    "    asc_pattern=re.compile(r'\\s(asc_[0-9a-zA-Z_\\.]+)')\n",
    "    unk_pattern=re.compile(r'\\s(unk_[0-9a-zA-Z_\\.]+)')\n",
    "    tbyte_pattern=re.compile(r'\\s(tbyte_[0-9a-zA-Z_\\.]+)')\n",
    "    qword_pattern=re.compile(r'\\s(qword_[0-9a-zA-Z_\\.]+)')\n",
    "    xmmword_pattern=re.compile(r'\\s(xmmword_[0-9a-zA-Z_\\.]+)')\n",
    "    long_pattern=re.compile(r'\\s(long_[0-9a-zA-Z_\\.]+)')\n",
    "    double_pattern=re.compile(r'\\s(double_[0-9a-zA-Z_\\.]+)')\n",
    "    array_pattern=re.compile(r'\\s(array_[0-9a-zA-Z_\\.]+)')\n",
    "    string_pattern=re.compile(r'\\s(string_[0-9a-zA-Z_\\.]+)')\n",
    "    arg_pattern=re.compile(r'\\s(arg_[0-9a-zA-Z_\\.]+)')\n",
    "    byte_pattern=re.compile(r'\\s(byte_[0-9a-zA-Z_\\.]+)')\n",
    "    sub_pattern=re.compile(r'\\s(sub_[0-9a-zA-Z_\\.]+)')\n",
    "    word_pattern=re.compile(r'\\s(word_[0-9a-zA-Z_\\.]+)')\n",
    "    locret_pattern=re.compile(r'\\s(locret_[0-9a-zA-Z_\\.]+)')\n",
    "    def_pattern=re.compile(r'\\s(def_[0-9a-zA-Z_\\.]+)')\n",
    "    off_pattern=re.compile(r'\\s(off_[0-9a-zA-Z_\\.]+)')\n",
    "    flt_pattern=re.compile(r'\\s(flt_[0-9a-zA-Z_\\.]+)')\n",
    "    dbl_pattern=re.compile(r'\\s(dbl_[0-9a-zA-Z_\\.]+)')\n",
    "    loc_pattern=re.compile(r'\\s(loc_[0-9a-zA-Z_\\.]+)')\n",
    "    stru_pattern=re.compile(r'\\s(stru_[0-9a-zA-Z_\\.]+)')\n",
    "    gpgrt_pattern=re.compile(r'\\s(gpgrt_[0-9a-zA-Z_\\.]+)')\n",
    "    gpg_pattern=re.compile(r'\\s(gpg_[0-9a-zA-Z_\\.]+)')\n",
    "    ymmword_pattern=re.compile(r'\\s(ymmword_[0-9a-zA-Z_\\.]+)')\n",
    "    buf_pattern=re.compile(r'\\s(buf_[0-9a-zA-Z_\\.]+)')\n",
    "    FILE_pattern=re.compile(r'\\s(FILE_[0-9a-zA-Z_\\.]+)')\n",
    "    callback_pattern=re.compile(r'\\s(callback_[0-9a-zA-Z_\\.]+)')\n",
    "    cb_pattern=re.compile(r'\\s(cb_[0-9a-zA-Z_\\.]+)')\n",
    "    CURLSH_pattern=re.compile(r'\\s(CURLSH_[0-9a-zA-Z_\\.]+)')\n",
    "    buffer_pattern=re.compile(r'\\s(buffer_[0-9a-zA-Z_\\.]+)')\n",
    "    CSWTCH_pattern=re.compile(r'\\s(CSWTCH_[0-9a-zA-Z_\\.]+)')\n",
    "    var_pattern=re.compile(r'\\s(var_[0-9a-zA-Z_\\.]+)')\n",
    "    str_pattern=re.compile(r'\\s(str_[0-9a-zA-Z_\\.]+)')\n",
    "    val_pattern=re.compile(r'\\s(val_[0-9a-zA-Z_\\.]+)')\n",
    "    pretty_function_pattern=re.compile(r'\\s(__PRETTY_FUNCTION___\\d+)')\n",
    "    algn_pattern=re.compile(r'\\s(algn_[0-9a-zA-Z_\\.]+)')\n",
    "    seg_pattern=re.compile(r'\\s(seg_[0-9a-zA-Z_\\.]+)')\n",
    "    src_pattern=re.compile(r'\\s(src_[0-9a-zA-Z_\\.]+)')\n",
    "    input_pattern=re.compile(r'\\s(input_[0-9a-zA-Z_\\.]+)')\n",
    "    local_pattern=re.compile(r'\\s(local_[0-9a-zA-Z_\\.]+)')\n",
    "    imm_pattern=re.compile(r'([\\s#\\.])imm[0-9a-zA-Z_\\.]+')\n",
    "    dummy_pattern=re.compile(r'([\\s#\\.])dummy[0-9a-zA-Z__]*')\n",
    "    std_pattern=re.compile(r'([\\s#\\.])std_[0-9a-zA-Z_\\.]+')\n",
    "    alloc_pattern=re.compile(r'\\s(alloc_[0-9a-zA-Z_]+)')\n",
    "\n",
    "    formatted_lines=[]\n",
    "    for line in lines:\n",
    "        original_line=line\n",
    "\n",
    "        line=aLarge_pattern.sub(' <STR>',line)\n",
    "        line=dword_pattern.sub(' <DWORD>',line)\n",
    "        line=jpt_pattern.sub(' <JPT>',line)\n",
    "        line=asc_pattern.sub(' <ASC>',line)\n",
    "        line=unk_pattern.sub(' <UNK>',line)\n",
    "        line=tbyte_pattern.sub(' <TBYTE>',line)\n",
    "        line=qword_pattern.sub(' <QWORD>',line)\n",
    "        line=xmmword_pattern.sub(' <XMMWORD>',line)\n",
    "        line=long_pattern.sub(' <LONG>',line)\n",
    "        line=double_pattern.sub(' <DOUBLE>',line)\n",
    "        line=array_pattern.sub(' <ARRAY>',line)\n",
    "        line=string_pattern.sub(' <STRING>',line)\n",
    "        line=arg_pattern.sub(' <ARG>',line)\n",
    "        line=byte_pattern.sub(' <BYTE>',line)\n",
    "        line=sub_pattern.sub(' <SUB>',line)\n",
    "        line=word_pattern.sub(' <WORD>',line)\n",
    "        line=locret_pattern.sub(' <LOCRET>',line)\n",
    "        line=def_pattern.sub(' <DEF>',line)\n",
    "        line=off_pattern.sub(' <OFF>',line)\n",
    "        line=flt_pattern.sub(' <FLT>',line)\n",
    "        line=dbl_pattern.sub(' <DBL>',line)\n",
    "        line=loc_pattern.sub(' <LOC>',line)\n",
    "        line=stru_pattern.sub(' <STRU>',line)\n",
    "        line=gpgrt_pattern.sub(' <GPGRT>',line)\n",
    "        line=gpg_pattern.sub(' <GPG>',line)\n",
    "        line=ymmword_pattern.sub(' <YMMWORD>',line)\n",
    "        line=buf_pattern.sub(' <BUF>',line)\n",
    "        line=FILE_pattern.sub(' <FILE>',line)\n",
    "        line=callback_pattern.sub(' <CALLBACK>',line)\n",
    "        line=cb_pattern.sub(' <CB>',line)\n",
    "        line=CURLSH_pattern.sub(' <CURLSH>',line)\n",
    "        line=buffer_pattern.sub(' <BUFFER>',line)\n",
    "        line=CSWTCH_pattern.sub(' <SCWTCH>',line)\n",
    "        line=var_pattern.sub(' <VAR>',line)\n",
    "        line=str_pattern.sub(' <STR>',line)\n",
    "        line=val_pattern.sub(' <VAL>',line)\n",
    "        line=pretty_function_pattern.sub(' <FUNC>',line)\n",
    "        line=algn_pattern.sub(\" <ALGN>\",line)\n",
    "        line=seg_pattern.sub(\" <SEG>\",line)\n",
    "        line=src_pattern.sub(\" <SRC>\",line)\n",
    "        line=input_pattern.sub(\" <INPUT>\",line)\n",
    "        line=local_pattern.sub(\" <LOCAL>\",line)\n",
    "        line=imm_pattern.sub(\" <IMM>\",line)\n",
    "        line=dummy_pattern.sub(\" <DUMMY>\",line)\n",
    "        line=std_pattern.sub(\" <STD>\",line)\n",
    "        line=alloc_pattern.sub(\" <ALLOC>\",line)\n",
    "\n",
    "        if original_line != line:\n",
    "            logging.info(f\"Formatting suffix: {original_line} -> {line}\")\n",
    "        \n",
    "        formatted_lines.append(line)\n",
    "    formatted_text='\\n'.join(formatted_lines)    \n",
    "    return formatted_text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_values(text):\n",
    "    \"\"\"\n",
    "    It identifies the hex value with '0x' prefix. If the digits exceeds 4, replace it\n",
    "    with '0x_VALUE', otherwise keep it. \n",
    "    \"\"\"\n",
    "    hex_pattern1 = re.compile(r'0x[a-fA-F0-9]+')# regular expression for hex value\n",
    "                                                  # more than 4 digits\n",
    "    #hex_pattern2 = re.compile(r'\\s[a-fA-F0-9]+h\\s')   \n",
    "    decimal_pattern=re.compile(r'\\s\\d+')                                           \n",
    "    lines = text.split('\\n') # Split the text into lines\n",
    "    converted_lines = []\n",
    "    for line in lines:\n",
    "        original_line=line\n",
    "        line = hex_pattern1.sub(' <HEX>', line)  # Apply the first pattern\n",
    "        #line = re.sub(hex_pattern2,' <HEX> ',line)  # Apply the second pattern\n",
    "        line = re.sub(decimal_pattern,' <VALUE>',line)\n",
    "        # if original_line != line:\n",
    "        #     logging.info(f\"Formatting VALUE: {original_line} -> {line}\")\n",
    "        converted_lines.append(line)\n",
    "    #it replaces all the patterns with 'hex_VALUE' in the line\n",
    "    # Return the processed text\n",
    "    return '\\n'.join(converted_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_TAG(text,dummy_set,opcode_set,register_set):\n",
    "        \n",
    "    #dash_var_pattern=re.compile(rf'(?!{opcode_pattern})[0-9a-zA-Z_\\.]+([_|\\.]+[0-9a-zA-Z]+[_]*)+')\n",
    "    #dash_var_pattern=re.compile(r'(?<![0-9a-zA-Z_\\.])[0-9a-zA-Z_\\.]+([_|\\.]+[0-9a-zA-Z]+[_]*)+(?=\\s)')\n",
    "    \n",
    "    tag_pattern1 = re.compile(r'\\b([a-zA-Z0-9\\.]+_[a-zA-Z0-9\\.]+)\\b')\n",
    "    tag_pattern2 = re.compile(r\"\\b([a-zA-Z0-9_\\.]{8,})\\b\")\n",
    "    \n",
    "    tag_pattern = re.compile(r'(?<![a-zA-Z0-9_\\.])(?<!\\.)[a-zA-Z0-9_\\.]{2,}(?=\\s)')\n",
    "\n",
    "    lines = text.split('\\n')\n",
    "    formatted_lines = []\n",
    "\n",
    "    for line in lines:\n",
    "        words2 = tag_pattern2.findall(line)\n",
    "        #This step guarantees the longer match is replaced first\n",
    "        words2.sort(key=len, reverse=True)\n",
    "        #logging.info(f\"The matched words include: {words}\")\n",
    "        formatted_line = line\n",
    "        for word in words2:\n",
    "            if word not in opcode_set|register_set|dummy_set:  \n",
    "                #logging.info(f\"The word <{word}> will be replaced.\")\n",
    "                formatted_line = re.sub(rf'\\b{word}\\b', \"<TAG>\", formatted_line)\n",
    "        \n",
    "        words1 = tag_pattern.findall(formatted_line)\n",
    "        words1.sort(key=len, reverse=True)\n",
    "        for word in words1:\n",
    "            if word not in opcode_set|register_set|dummy_set:  \n",
    "                #logging.info(f\"The word <{word}> will be replaced.\")\n",
    "                formatted_line = re.sub(rf'\\b{word}\\b', \"<TAG>\", formatted_line)      \n",
    "\n",
    "        if formatted_line!=line:\n",
    "            logging.info(f\"Formatting TAG: {line} -> {formatted_line}\")\n",
    "\n",
    "        formatted_lines.append(formatted_line)\n",
    "\n",
    "        # Join the formatted lines back into text\n",
    "    formatted_text = '\\n'.join(formatted_lines)\n",
    "    return formatted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_words(text, opcode_set,register_set,dummy_set):\n",
    "    #This function replaces the words longer than 3 letters with <TAG> except\n",
    "    #for the opcode\n",
    "    lines = text.split('\\n')\n",
    "    formatted_lines = []\n",
    "    \n",
    "    \n",
    "    words_pattern = re.compile(r'[a-zA-Z0-9]{5,}(?=\\s)')  # Regular expression pattern to match lowercase words with more than 3 letters\n",
    "    for line in lines:\n",
    "        words = words_pattern.findall(line)\n",
    "        #This step guarantees the longer match is replaced first\n",
    "        words.sort(key=len, reverse=True)\n",
    "        formatted_line = line\n",
    "        for word in words:\n",
    "            if word not in opcode_set|register_set|dummy_set:\n",
    "                logging.info(f\"The word <{word}> is not in any sets and will be replaced \")\n",
    "                formatted_line = re.sub(rf'\\b{word}\\b', \"<TAG>\", formatted_line)\n",
    "                #formatted_line = formatted_line.replace(word, \"<TAG>\")\n",
    "        if formatted_line!=line:\n",
    "            logging.info(f\"Formatting WORD: {line} -> {formatted_line}\")\n",
    "\n",
    "        formatted_lines.append(formatted_line)\n",
    "   \n",
    "    return '\\n'.join(formatted_lines)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_comments(text):\n",
    "    \"\"\"\n",
    "    Removes comments that appear after \"//\" and ';' in each line.\n",
    "\n",
    "    Parameters:\n",
    "    - text (str): The input text from which to remove the comments.\n",
    "\n",
    "    Returns:\n",
    "    - str: The text with comments removed.\n",
    "    \"\"\"\n",
    "    # Split the text into lines\n",
    "    lines = text.split('\\n')\n",
    "    # Remove comments from each line\n",
    "    cleaned_lines = [line.split('//')[0].rstrip() for line in lines]\n",
    "    cleaned_lines2=[line.split(';')[0].rstrip() for line in cleaned_lines]\n",
    "    cleaned_lines3=[line.split('\"')[0].rstrip() for line in cleaned_lines2]# the content after '\"' should also be deleted. \n",
    "    cleaned_lines4 = [line.split('node')[0] + 'node' if 'node' in line else line for line in cleaned_lines3]\n",
    "    cleaned_lines5=[line.split('#')[0].rstrip() for line in cleaned_lines4]\n",
    "    # Join the lines back into a single string\n",
    "    return '\\n'.join(cleaned_lines5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_extra_lines(text):\n",
    "    \"\"\"\n",
    "    Removes lines that contain 'colorentry' and the numbers that follow.\n",
    "    We also remove the lines that start with 'edge:'. \n",
    "    We don't need those information. \n",
    "\n",
    "    Parameters:\n",
    "    - text (str): The input text from which to remove the lines.\n",
    "\n",
    "    Returns:\n",
    "    - str: The text with 'colorentry' lines removed.\n",
    "    \"\"\"\n",
    "    # Split the text into lines\n",
    "    lines = text.split('\\n')\n",
    "    # Remove lines containing 'colorentry'\n",
    "    lines=lines[10:]\n",
    "    cleaned_lines = [line for line in lines if not line.startswith('colorentry')\n",
    "                     |line.startswith('edge')|line.startswith('}')|line.startswith('IMPORT')|line.startswith('.extern')]\n",
    "    # Join the lines back into a single string\n",
    "    return '\\n'.join(cleaned_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    lines=text.split('\\n')\n",
    "    for i,line in enumerate(lines):\n",
    "        token_pattern=re.compile(r'([\\[\\]\\+\\:\\-\\(\\)\\*\\{\\}])')\n",
    "        prefix_pattern=re.compile(r'(@)')\n",
    "        replace_pattern=re.compile(r'(\\,)')\n",
    "        sign_matches=token_pattern.findall(line) \n",
    "        line = replace_pattern.sub(r' ',line)\n",
    "        line = prefix_pattern.sub(r' \\1', line)\n",
    "        line = token_pattern.sub(r' \\1 ', line)\n",
    "        line = re.sub(r'\\s+', ' ', line)\n",
    "        lines[i] = line\n",
    "    return '\\n'.join(lines)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_empty_lines(text):\n",
    "    '''\n",
    "    This function is used to delete empty lines in the formatted gdl file. \n",
    "    It also removed the fode information\n",
    "    '''\n",
    "    lines=text.split('\\n')\n",
    "    new_lines=[line for line in lines if line.strip()!='']\n",
    "    cleaned_text='\\n'.join(new_lines)\n",
    "    return cleaned_text  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formulate_sentence(text):\n",
    "    #this function formulates all the instructions within one node to a whole sentence. \n",
    "    #it also deletes all the commas in the text \n",
    "    lines=text.split('\\n')\n",
    "    output=''\n",
    "    current_line=''\n",
    "    for line in lines:\n",
    "        if line.strip()=='node':\n",
    "            if current_line:\n",
    "                output+=current_line.strip().replace(\",\", \"\")+'\\n'\n",
    "                current_line=\"\"\n",
    "        else:\n",
    "            current_line+=line.strip().replace(\",\", \"\")+' <E> '\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(gdl_file_path, output_path, func_dict,opcode_set,register_set,dummy_set):\n",
    "    \"\"\"\n",
    "    Reads a GDL file, applies cleaning functions, and writes the output to a new file.\n",
    "\n",
    "    Parameters:\n",
    "    - gdl_file_path (str): The path to the GDL file to be processed.\n",
    "    \"\"\"\n",
    "    # Extract the directory and the base name of the gdl file\n",
    "    file_dir, base_name = os.path.split(gdl_file_path)\n",
    "    #print(f\"the file directory is {file_dir}\")\n",
    "    #output_file_dir=file_dir.split('/')[-1]\n",
    "\n",
    "    #The following command is to remove the version information so the comparison is easier\n",
    "    new_output_file_dir=(file_dir.split('-')[0]+'-'+file_dir.split('-')[-1]).split('/')[-1]\n",
    "    #print(f\"the new output file directory is {new_output_file_dir}\")\n",
    "    #print(f\"the output file directory is {output_file_dir}\")\n",
    "    # Remove the '.gdl' extension and add '_postprocessed'\n",
    "    output_base_name = base_name[:-4]\n",
    "    #output_file_path = os.path.join(file_dir, output_base_name)\n",
    "    #print(f\"the output file path is {output_base_name}\")  \n",
    "    output_name=new_output_file_dir+'-'+output_base_name\n",
    "    #print(f\"the output name is {output_name}\")\n",
    "    output_file_path=os.path.join(output_path,output_name)\n",
    "\n",
    "#     if output_name.split('-')[0] not in{'binutils','openssl','findutils','libgpg'}:\n",
    "#          logging.info(f\"{gdl_file_path} not in the training dataset, skipping. \")\n",
    "#          return\n",
    "\n",
    "    if os.path.exists(output_file_path):\n",
    "        logging.info(f\"Skipping file: {output_file_path} (output file already exists)\")\n",
    "        return\n",
    "\n",
    "    # Read the input GDL file\n",
    "    with open(gdl_file_path, 'r') as file:\n",
    "         text = file.read()\n",
    "\n",
    "    text = remove_extra_lines(text)\n",
    "    text = remove_comments(text)\n",
    "    text = remove_empty_lines(text)\n",
    "    #text = format_call_func(text)\n",
    "\n",
    "    #text=format_call_func(text)\n",
    "    text = tokenize(text)\n",
    "    # the last parameter corresponds to the lib: findutils, libgpg, openssl etc\n",
    "    #text = format_func_names(text,func_dict,new_output_file_dir.split('-')[0]) \n",
    "    text = format_suffix_vars(text)\n",
    "    \n",
    "    text = format_values(text) \n",
    "    text = format_TAG(text,opcode_set,register_set,dummy_set)\n",
    "    #text = replace_words(text,opcode_set,register_set,dummy_set)\n",
    "    text = formulate_sentence(text)\n",
    "    \n",
    "    #Write the cleaned text to the output file\n",
    "    with open(output_file_path, 'w') as file:\n",
    "         file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    ISA='ppc32'\n",
    "    log_path = f\"../original_dataset/gdl_pb_formatted/log/{ISA}\"\n",
    "    os.makedirs(log_path, exist_ok=True)\n",
    "    log_file = os.path.join(log_path, f\"{ISA}_formatting.log\")\n",
    "    logging.basicConfig(filename=log_file, level=logging.INFO, format='%(message)s')\n",
    "    \n",
    "    # Use glob to find all '.gdl' files recursively in the current folder and sub-folders\n",
    "    input_path = glob.glob(f'../original_dataset/gdl_pb/{ISA}_malware/*.gdl', recursive=True)\n",
    "    #input_path = glob.glob(f'../original_dataset/gdl_pb/{ISA}/**/**/*.gdl', recursive=True)\n",
    "    #print(input_path)\n",
    "    output_path=f\"../original_dataset/gdl_pb_formatted/{ISA}_malware\"\n",
    "    #output_path=f\"../Malware_detection_files/tensors/{ISA}_translation/{ISA}_malware\"\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    #opcode_set_path=f'../original_dataset/opcode_operand/{ISA}/{ISA}_opcode_counts.txt'\n",
    "    #register_set_path=f'../original_dataset/opcode_operand/{ISA}/register_counts.txt'\n",
    "\n",
    "    zlib_func_set_path='../original_dataset/func_set/ppc32_func_set/ppc32_zlib-1.2.11-bin_func.txt'\n",
    "    binutils_func_set_path='../original_dataset/func_set/ppc32_func_set/ppc32_binutils-2.34-bin_func.txt'\n",
    "    coreutils_func_set_path='../original_dataset/func_set/ppc32_func_set/ppc32_coreutils-9.0-bin_func.txt'\n",
    "    curl_func_set_path='../original_dataset/func_set/ppc32_func_set/ppc32_curl-7.87.0-bin_func.txt'\n",
    "    diffutils_func_set_path='../original_dataset/func_set/ppc32_func_set/ppc32_diffutils-3.7-bin_func.txt'\n",
    "    findutils_func_set_path='../original_dataset/func_set/ppc32_func_set/ppc32_findutils-4.8.0-bin_func.txt'\n",
    "    libgpg_error_func_set_path='../original_dataset/func_set/ppc32_func_set/ppc32_libgpg-error-1.45-bin_func.txt'\n",
    "    openssl_func_set_path='../original_dataset/func_set/ppc32_func_set/ppc32_openssl-1.1.1p-bin_func.txt'\n",
    "\n",
    "    zlib_func_set=set()\n",
    "    binutils_func_set=set()\n",
    "    coreutils_func_set=set()\n",
    "    curl_func_set=set()\n",
    "    diffutils_func_set=set()\n",
    "    findutils_func_set=set()\n",
    "    libgpg_error_func_set=set()\n",
    "    openssl_func_set=set()\n",
    "\n",
    "    with open(zlib_func_set_path,'r') as file:\n",
    "        for line in file:\n",
    "            zlib_func_set.add(line.strip())  \n",
    "\n",
    "    with open(binutils_func_set_path,'r') as file:\n",
    "        for line in file:\n",
    "            binutils_func_set.add(line.strip())   \n",
    "\n",
    "    with open(coreutils_func_set_path,'r') as file:\n",
    "        for line in file:\n",
    "            coreutils_func_set.add(line.strip())  \n",
    "\n",
    "    with open(curl_func_set_path,'r') as file:\n",
    "        for line in file:\n",
    "            curl_func_set.add(line.strip())  \n",
    "\n",
    "    with open(diffutils_func_set_path,'r') as file:\n",
    "        for line in file:\n",
    "            diffutils_func_set.add(line.strip())  \n",
    "\n",
    "    with open(findutils_func_set_path,'r') as file:\n",
    "        for line in file:\n",
    "            findutils_func_set.add(line.strip())  \n",
    "\n",
    "    with open(libgpg_error_func_set_path,'r') as file:\n",
    "        for line in file:\n",
    "            libgpg_error_func_set.add(line.strip())  \n",
    "\n",
    "    with open(openssl_func_set_path,'r') as file:\n",
    "        for line in file:\n",
    "            openssl_func_set.add(line.strip())        \n",
    "\n",
    "    func_dict={'zlib':zlib_func_set, 'binutils':binutils_func_set,'openssl':openssl_func_set, \n",
    "               'findutils':findutils_func_set,'diffutils':diffutils_func_set,'libgpg_error':libgpg_error_func_set,\n",
    "               'curl':curl_func_set,'coreutils':coreutils_func_set}\n",
    "\n",
    "    # Process each file\n",
    "    for gdl_file_path in input_path:\n",
    "        #if gdl_file_path.split('-')[0] in{'binutils','openssl','findutils','libgpg'}:\n",
    "        process_file(gdl_file_path, output_path,func_dict,opcode_set,register_set,dummy_set)\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
