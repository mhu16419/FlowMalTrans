{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob # folder operations\n",
    "import re # use regular expressions\n",
    "import logging \n",
    "# You perpahs need to restart the kernel in .ipynb to make the log module working normally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_func_names(text, func_dict,lib):\n",
    "\n",
    "    if lib=='binutils':\n",
    "        func_set=func_dict['binutils']\n",
    "    elif lib=='coreutils':\n",
    "        func_set=func_dict['coreutils']\n",
    "    elif lib=='curl':\n",
    "        func_set=func_dict['curl']\n",
    "    elif lib=='diffutils':\n",
    "        func_set=func_dict['diffutils']\n",
    "    elif lib=='findutils':\n",
    "        func_set=func_dict['findutils']\n",
    "    elif lib=='libgpg':\n",
    "        func_set=func_dict['libgpg_error']    \n",
    "    elif lib=='openssl':\n",
    "        func_set=func_dict['openssl']\n",
    "    elif lib=='zlib':\n",
    "        func_set=func_dict['zlib']\n",
    "    else: \n",
    "        func_set=set()\n",
    "        print(f\"Warning, undetected library: {lib}\")                        \n",
    "\n",
    "    pattern=r'\\b(' + '|'.join(func_set) + r')\\b'\n",
    "    # Split the text into lines\n",
    "    lines = text.split('\\n')\n",
    "    formatted_lines = []\n",
    "\n",
    "    # Iterate over each line\n",
    "    for line in lines:\n",
    "        # Split the line into the first word and the rest of the line\n",
    "        parts = line.split(' ', 1)\n",
    "        first_word = parts[0]\n",
    "        rest_of_line = parts[1] if len(parts) > 1 else ''\n",
    "        #original_line=rest_of_line\n",
    "        # Replace occurrences of any function name in the rest of the line with '<FUNC>'\n",
    "        modified_rest_of_line = re.sub(r'_\\b(' + '|'.join(func_set) + r')\\b', '<FUNC>', rest_of_line)\n",
    "        modified_rest_of_line = re.sub(pattern, '<FUNC>', rest_of_line)\n",
    "        #modified_rest_of_line = re.sub(underscore_pattern, '<FUNC>', modified_rest_of_line)\n",
    "        #print(pattern)\n",
    "        # Concatenate the first word and the modified rest of the line\n",
    "        # if original_line != modified_rest_of_line:\n",
    "        #     logging.info(f\"Formatting function: {original_line} -> {modified_rest_of_line}\")\n",
    "\n",
    "        formatted_line = first_word + (' ' + modified_rest_of_line if modified_rest_of_line else '')\n",
    "        formatted_lines.append(formatted_line)\n",
    "\n",
    "    # Join the formatted lines back into text\n",
    "    formatted_text = '\\n'.join(formatted_lines)\n",
    "    return formatted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_suffix_vars(text):\n",
    "    lines=text.split('\\n')\n",
    "    #opcode_pattern='|'.join(re.escape(opcode) for opcode in opcode_set)\n",
    "\n",
    "    aLarge_pattern=re.compile(r'(?<![a-zA-Z_])a[A-Z][a-z0-9A-Z]+\\_*\\d*')# match anything except for a lower or upper case letter\n",
    "    dword_pattern=re.compile(r'(?<![a-zA-Z_])dword_[0-9a-zA-Z_]+')\n",
    "    jpt_pattern=re.compile(r'(?<![a-zA-Z_])jpt_[0-9a-zA-Z_]+')\n",
    "    asc_pattern=re.compile(r'(?<![a-zA-Z_])asc_[0-9a-zA-Z_]+')\n",
    "    unk_pattern=re.compile(r'(?<![a-zA-Z_])unk_[0-9a-zA-Z_]+')\n",
    "    tbyte_pattern=re.compile(r'(?<![a-zA-Z_])tbyte_[0-9a-zA-Z_]+')\n",
    "    qword_pattern=re.compile(r'(?<![a-zA-Z_])qword_[0-9a-zA-Z_]+')\n",
    "    xmmword_pattern=re.compile(r'(?<![a-zA-Z_])xmmword_[0-9a-zA-Z_]+')\n",
    "    long_pattern=re.compile(r'(?<![a-zA-Z_])long_[0-9a-zA-Z_]+')\n",
    "    double_pattern=re.compile(r'(?<![a-zA-Z_])double_[0-9a-zA-Z_]+')\n",
    "    array_pattern=re.compile(r'(?<![a-zA-Z_])array_[0-9a-zA-Z_]+')\n",
    "    string_pattern=re.compile(r'(?<![a-zA-Z_])string_[0-9a-zA-Z_]+')\n",
    "    arg_pattern=re.compile(r'(?<![a-zA-Z_])arg_[0-9a-zA-Z_]+')\n",
    "    byte_pattern=re.compile(r'(?<![a-zA-Z_])byte_[0-9a-zA-Z_]+')\n",
    "    sub_pattern=re.compile(r'(?<![a-zA-Z_])sub_[0-9a-zA-Z_]+')\n",
    "    word_pattern=re.compile(r'(?<![a-zA-Z_])word_[0-9a-zA-Z_]+')\n",
    "    locret_pattern=re.compile(r'(?<![a-zA-Z_])locret_[0-9a-zA-Z_]+')\n",
    "    def_pattern=re.compile(r'(?<![a-zA-Z_])def_[0-9a-zA-Z_]+')\n",
    "    off_pattern=re.compile(r'(?<![a-zA-Z_])off_[0-9a-zA-Z_]+')\n",
    "    flt_pattern=re.compile(r'(?<![a-zA-Z_])flt_[0-9a-zA-Z_]+')\n",
    "    dbl_pattern=re.compile(r'(?<![a-zA-Z_])dbl_[0-9a-zA-Z_]+')\n",
    "    loc_pattern=re.compile(r'(?<![a-zA-Z_])loc_[0-9a-zA-Z_]+')\n",
    "    stru_pattern=re.compile(r'(?<![a-zA-Z_])stru_[0-9a-zA-Z_]+')\n",
    "    gpgrt_pattern=re.compile(r'(?<![a-zA-Z_])gpgrt_[0-9a-zA-Z_]+')\n",
    "    gpg_pattern=re.compile(r'(?<![a-zA-Z_])gpg_[0-9a-zA-Z_]+')\n",
    "    ymmword_pattern=re.compile(r'(?<![a-zA-Z_])ymmword_[0-9a-zA-Z_]+')\n",
    "    buf_pattern=re.compile(r'(?<![a-zA-Z_])buf_[0-9a-zA-Z_]+')\n",
    "    FILE_pattern=re.compile(r'(?<![a-zA-Z_])FILE_[0-9a-zA-Z_]+')\n",
    "    callback_pattern=re.compile(r'(?<![a-zA-Z_])callback_[0-9a-zA-Z_]+')\n",
    "    cb_pattern=re.compile(r'(?<![a-zA-Z_])cb_[0-9a-zA-Z_]+')\n",
    "    CURLSH_pattern=re.compile(r'(?<![a-zA-Z_])CURLSH_[0-9a-zA-Z_]+')\n",
    "    buffer_pattern=re.compile(r'(?<![a-zA-Z_])buffer_[0-9a-zA-Z_]+')\n",
    "    CSWTCH_pattern=re.compile(r'(?<![a-zA-Z_])CSWTCH_[0-9a-zA-Z_]+')\n",
    "    var_pattern=re.compile(r'(?<![a-zA-Z_])var_[0-9a-zA-Z_]+')\n",
    "    str_pattern=re.compile(r'(?<![a-zA-Z_])str_[0-9a-zA-Z_]+')\n",
    "    val_pattern=re.compile(r'(?<![a-zA-Z_])val_[0-9a-zA-Z_]+')\n",
    "    pretty_function_pattern=re.compile(r'(?<![a-zA-Z_])__PRETTY_FUNCTION___\\d+')\n",
    "    algn_pattern=re.compile(r'(?<![a-zA-Z_])algn_[0-9a-zA-Z_]+')\n",
    "    seg_pattern=re.compile(r'(?<![a-zA-Z_])seg_[0-9a-zA-Z_]+')\n",
    "    src_pattern=re.compile(r'(?<![a-zA-Z_])src_[0-9a-zA-Z_]+')\n",
    "    input_pattern=re.compile(r'(?<![a-zA-Z_])input_[0-9a-zA-Z_]+')\n",
    "    local_pattern=re.compile(r'(?<![a-zA-Z_])local_[0-9a-zA-Z_]+')\n",
    "    imm_pattern=re.compile(r'([\\s#\\.])imm[0-9a-zA-Z_]+')\n",
    "    dummy_pattern=re.compile(r'([\\s#\\.])dummy[0-9a-zA-Z__]*')\n",
    "    std_pattern=re.compile(r'([\\s#\\.])std_[0-9a-zA-Z_]+')\n",
    "    alloc_pattern=re.compile(r'(?<![a-zA-Z_])alloc_[0-9a-zA-Z_]+')\n",
    "\n",
    "    formatted_lines=[]\n",
    "    for line in lines:\n",
    "        original_line=line\n",
    "\n",
    "        line=aLarge_pattern.sub('<STR>',line)\n",
    "        line=dword_pattern.sub('<DWORD>',line)\n",
    "        line=jpt_pattern.sub('<JPT>',line)\n",
    "        line=asc_pattern.sub('<ASC>',line)\n",
    "        line=unk_pattern.sub('<UNK>',line)\n",
    "        line=tbyte_pattern.sub('<TBYTE>',line)\n",
    "        line=qword_pattern.sub('<QWORD>',line)\n",
    "        line=xmmword_pattern.sub('<XMMWORD>',line)\n",
    "        line=long_pattern.sub('<LONG>',line)\n",
    "        line=double_pattern.sub('<DOUBLE>',line)\n",
    "        line=array_pattern.sub('<ARRAY>',line)\n",
    "        line=string_pattern.sub('<STRING>',line)\n",
    "        line=arg_pattern.sub('<ARG>',line)\n",
    "        line=byte_pattern.sub('<BYTE>',line)\n",
    "        line=sub_pattern.sub('<SUB>',line)\n",
    "        line=word_pattern.sub('<WORD>',line)\n",
    "        line=locret_pattern.sub('<LOCRET>',line)\n",
    "        line=def_pattern.sub('<DEF>',line)\n",
    "        line=off_pattern.sub('<OFF>',line)\n",
    "        line=flt_pattern.sub('<FLT>',line)\n",
    "        line=dbl_pattern.sub('<DBL>',line)\n",
    "        line=loc_pattern.sub('<LOC>',line)\n",
    "        line=stru_pattern.sub('<STRU>',line)\n",
    "        line=gpgrt_pattern.sub('<GPGRT>',line)\n",
    "        line=gpg_pattern.sub('<GPG>',line)\n",
    "        line=ymmword_pattern.sub('<YMMWORD>',line)\n",
    "        line=buf_pattern.sub('<BUF>',line)\n",
    "        line=FILE_pattern.sub('<FILE>',line)\n",
    "        line=callback_pattern.sub('<CALLBACK>',line)\n",
    "        line=cb_pattern.sub('<CB>',line)\n",
    "        line=CURLSH_pattern.sub('<CURLSH>',line)\n",
    "        line=buffer_pattern.sub('<BUFFER>',line)\n",
    "        line=CSWTCH_pattern.sub('<SCWTCH>',line)\n",
    "        line=var_pattern.sub('<VAR>',line)\n",
    "        line=str_pattern.sub('<STR>',line)\n",
    "        line=val_pattern.sub('<VAL>',line)\n",
    "        line=pretty_function_pattern.sub('<FUNC>',line)\n",
    "        line=algn_pattern.sub(\"<ALGN>\",line)\n",
    "        line=seg_pattern.sub(\"<SEG>\",line)\n",
    "        line=src_pattern.sub(\"<SRC>\",line)\n",
    "        line=input_pattern.sub(\"<INPUT>\",line)\n",
    "        line=local_pattern.sub(\"<LOCAL>\",line)\n",
    "        line=imm_pattern.sub(\"<IMM>\",line)\n",
    "        line=dummy_pattern.sub(\"<DUMMY>\",line)\n",
    "        line=std_pattern.sub(\"<STD>\",line)\n",
    "        line=alloc_pattern.sub(\"<ALLOC>\",line)\n",
    "\n",
    "        if original_line != line:\n",
    "            logging.info(f\"Formatting suffix: {original_line} -> {line}\")\n",
    "        \n",
    "        formatted_lines.append(line)\n",
    "    formatted_text='\\n'.join(formatted_lines)    \n",
    "    return formatted_text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_TAG(text,dummy_set,opcode_set,register_set):\n",
    "        \n",
    "    #dash_var_pattern=re.compile(rf'(?!{opcode_pattern})[0-9a-zA-Z_\\.]+([_|\\.]+[0-9a-zA-Z]+[_]*)+')\n",
    "    #dash_var_pattern=re.compile(r'(?<![0-9a-zA-Z_\\.])[0-9a-zA-Z_\\.]+([_|\\.]+[0-9a-zA-Z]+[_]*)+(?![0-9a-zA-Z_\\.])')\n",
    "    #tag_pattern = re.compile(r'(?<![a-zA-Z0-9_\\.])[a-zA-Z0-9_\\.]{2,}')\n",
    "    tag_pattern = re.compile(r'(?<![a-zA-Z0-9_\\.])(?<!\\.)[a-zA-Z0-9_\\.]{3,}(?![a-zA-Z0-9_\\.])')\n",
    "    #tag2_pattern=re.compile(r'(?<![0-9a-zA-Z_\\.])(_[a-zA-Z0-9]+)|(([a-zA-Z0-9]+)_)(?![0-9a-zA-Z_\\.])')\n",
    "\n",
    "    lines = text.split('\\n')\n",
    "    formatted_lines = []\n",
    "\n",
    "    for line in lines:\n",
    "        words = tag_pattern.findall(line)\n",
    "        #logging.info(f\"The matched words include: {words}\")\n",
    "        formatted_line = line\n",
    "        for word in words:\n",
    "            if word not in opcode_set|register_set|dummy_set:   \n",
    "                formatted_line = formatted_line.replace(word, \"<TAG>\")\n",
    "        if formatted_line!=line:\n",
    "            logging.info(f\"Formatting TAG: {line} -> {formatted_line}\")\n",
    "\n",
    "        formatted_lines.append(formatted_line)\n",
    "\n",
    "        # Iterate over each line\n",
    "    # for line in lines:\n",
    "    #         # Split the line into the first word and the rest of the line\n",
    "    #         parts = line.split(' ', 1)\n",
    "    #         first_word = parts[0]\n",
    "    #         rest_of_line = parts[1] if len(parts) > 1 else ''\n",
    "            \n",
    "    #         modified_rest_of_line = dash_var_pattern.sub('<TAG>', rest_of_line)\n",
    "    #         modified_rest_of_line = tag2_pattern.sub('<TAG>', rest_of_line)\n",
    "    #         #modified_rest_of_line = re.sub(underscore_pattern, '<FUNC>', modified_rest_of_line)\n",
    "    #         #print(pattern)\n",
    "    #         # Concatenate the first word and the modified rest of the line\n",
    "    #         # if original_line != modified_rest_of_line:\n",
    "    #         #     logging.info(f\"Formatting function: {original_line} -> {modified_rest_of_line}\")\n",
    "\n",
    "    #         formatted_line = first_word + (' ' + modified_rest_of_line if modified_rest_of_line else '')\n",
    "    #         if formatted_line != line:\n",
    "    #             logging.info(f\"Formatting TAG: {line} -> {formatted_line}\")\n",
    "    #         formatted_lines.append(formatted_line)\n",
    "\n",
    "        # Join the formatted lines back into text\n",
    "    formatted_text = '\\n'.join(formatted_lines)\n",
    "    return formatted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_values(text):\n",
    "    \"\"\"\n",
    "    It identifies the hex value with '0x' prefix. If the digits exceeds 4, replace it\n",
    "    with '0x_VALUE', otherwise keep it. \n",
    "    \"\"\"\n",
    "    hex_pattern1 = re.compile(r'0x[a-fA-F0-9]+')# regular expression for hex value\n",
    "                                                  # more than 4 digits\n",
    "    hex_pattern2 = re.compile(r'\\s[a-fA-F0-9]+h\\s')   \n",
    "    decimal_pattern=re.compile(r'\\s\\d+')                                           \n",
    "    lines = text.split('\\n') # Split the text into lines\n",
    "    converted_lines = []\n",
    "    for line in lines:\n",
    "        original_line=line\n",
    "        line = hex_pattern1.sub('<HEX>', line)  # Apply the first pattern\n",
    "        line = re.sub(hex_pattern2,' <HEX> ',line)  # Apply the second pattern\n",
    "        line = re.sub(decimal_pattern,' <VALUE>',line)\n",
    "        if original_line != line:\n",
    "            logging.info(f\"Formatting VALUE: {original_line} -> {line}\")\n",
    "        converted_lines.append(line)\n",
    "    #it replaces all the patterns with 'hex_VALUE' in the line\n",
    "    # Return the processed text\n",
    "    return '\\n'.join(converted_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_words(text, opcode_set,register_set,dummy_set):\n",
    "    #This function replaces the words longer than 3 letters with <TAG> except\n",
    "    #for the opcode\n",
    "    lines = text.split('\\n')\n",
    "    formatted_lines = []\n",
    "    \n",
    "    \n",
    "    words_pattern = re.compile(r'[a-zA-Z0-9]{2,}')  # Regular expression pattern to match lowercase words with more than 3 letters\n",
    "    for line in lines:\n",
    "        words = words_pattern.findall(line)\n",
    "        formatted_line = line\n",
    "        for word in words:\n",
    "            if word not in opcode_set|register_set|dummy_set:\n",
    "                formatted_line = formatted_line.replace(word, \"<TAG>\")\n",
    "        if formatted_line!=line:\n",
    "            logging.info(f\"Formatting WORD: {line} -> {formatted_line}\")\n",
    "\n",
    "        formatted_lines.append(formatted_line)\n",
    "   \n",
    "    return '\\n'.join(formatted_lines)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_comments(text):\n",
    "    \"\"\"\n",
    "    Removes comments that appear after \"//\" and ';' in each line.\n",
    "\n",
    "    Parameters:\n",
    "    - text (str): The input text from which to remove the comments.\n",
    "\n",
    "    Returns:\n",
    "    - str: The text with comments removed.\n",
    "    \"\"\"\n",
    "    # Split the text into lines\n",
    "    lines = text.split('\\n')\n",
    "    # Remove comments from each line\n",
    "    cleaned_lines = [line.split('//')[0].rstrip() for line in lines]\n",
    "    cleaned_lines2=[line.split(';')[0].rstrip() for line in cleaned_lines]\n",
    "    cleaned_lines3=[line.split('\"')[0].rstrip() for line in cleaned_lines2]# the content after '\"' should also be deleted. \n",
    "    cleaned_lines4 = [line.split('node')[0] + 'node' if 'node' in line else line for line in cleaned_lines3]\n",
    "    cleaned_lines5=[line.split('#')[0].rstrip() for line in cleaned_lines4]\n",
    "    # Join the lines back into a single string\n",
    "    return '\\n'.join(cleaned_lines5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_extra_lines(text):\n",
    "    \"\"\"\n",
    "    Removes lines that contain 'colorentry' and the numbers that follow.\n",
    "    We also remove the lines that start with 'edge:'. \n",
    "    We don't need those information. \n",
    "\n",
    "    Parameters:\n",
    "    - text (str): The input text from which to remove the lines.\n",
    "\n",
    "    Returns:\n",
    "    - str: The text with 'colorentry' lines removed.\n",
    "    \"\"\"\n",
    "    # Split the text into lines\n",
    "    lines = text.split('\\n')\n",
    "    # Remove lines containing 'colorentry'\n",
    "    lines=lines[10:]\n",
    "    cleaned_lines = [line for line in lines if not line.startswith('colorentry')\n",
    "                     |line.startswith('edge')|line.startswith('nop')|line.startswith('}')|line.startswith('IMPORT')|line.startswith('.extern')]\n",
    "    # Join the lines back into a single string\n",
    "    return '\\n'.join(cleaned_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    lines=text.split('\\n')\n",
    "    for i,line in enumerate(lines):\n",
    "        token_pattern=re.compile(r'([\\[\\]\\+\\:\\-\\(\\)\\*])')\n",
    "        replace_pattern=re.compile(r'(\\,)')\n",
    "        sign_matches=token_pattern.findall(line) \n",
    "        line = replace_pattern.sub(r' ',line)\n",
    "        line = token_pattern.sub(r' \\1 ', line)\n",
    "        line = re.sub(r'\\s+', ' ', line)\n",
    "        lines[i] = line\n",
    "    return '\\n'.join(lines)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_empty_lines(text):\n",
    "    '''\n",
    "    This function is used to delete empty lines in the formatted gdl file. \n",
    "    It also removed the fode information\n",
    "    '''\n",
    "    lines=text.split('\\n')\n",
    "    new_lines=[line for line in lines if line.strip()!='']\n",
    "    cleaned_text='\\n'.join(new_lines)\n",
    "    return cleaned_text  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formulate_sentence(text):\n",
    "    #this function formulates all the instructions within one node to a whole sentence. \n",
    "    #it also deletes all the commas in the text \n",
    "    lines=text.split('\\n')\n",
    "    output=''\n",
    "    current_line=''\n",
    "    for line in lines:\n",
    "        if line.strip()=='node':\n",
    "            if current_line:\n",
    "                output+=current_line.strip().replace(\",\", \"\")+'\\n'\n",
    "                current_line=\"\"\n",
    "        else:\n",
    "            current_line+=line.strip().replace(\",\", \"\")+' <E> '\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(gdl_file_path, output_path, func_dict,opcode_set,register_set,dummy_set):\n",
    "    \"\"\"\n",
    "    Reads a GDL file, applies cleaning functions, and writes the output to a new file.\n",
    "\n",
    "    Parameters:\n",
    "    - gdl_file_path (str): The path to the GDL file to be processed.\n",
    "    \"\"\"\n",
    "    # Extract the directory and the base name of the gdl file\n",
    "    file_dir, base_name = os.path.split(gdl_file_path)\n",
    "    #print(f\"the file directory is {file_dir}\")\n",
    "    #output_file_dir=file_dir.split('/')[-1]\n",
    "\n",
    "    #The following command is to remove the version information so the comparison is easier\n",
    "    new_output_file_dir=(file_dir.split('-')[0]+'-'+file_dir.split('-')[-1]).split('/')[-1]\n",
    "    #print(f\"the new output file directory is {new_output_file_dir}\")\n",
    "    #print(f\"the output file directory is {output_file_dir}\")\n",
    "    # Remove the '.gdl' extension and add '_postprocessed'\n",
    "    output_base_name = base_name[:-4]\n",
    "    #output_file_path = os.path.join(file_dir, output_base_name)\n",
    "    #print(f\"the output file path is {output_base_name}\")  \n",
    "    output_name=new_output_file_dir+'-'+output_base_name\n",
    "    #print(f\"the output name is {output_name}\")\n",
    "    output_file_path=os.path.join(output_path,output_name)\n",
    "    # Read the input GDL file\n",
    "    with open(gdl_file_path, 'r') as file:\n",
    "         text = file.read()\n",
    "\n",
    "    text = remove_extra_lines(text)\n",
    "    text = remove_comments(text)\n",
    "    text = remove_empty_lines(text)\n",
    "    #text = format_call_func(text)\n",
    "    \n",
    "    text = tokenize(text)\n",
    "    # the last parameter corresponds to the lib: findutils, libgpg, openssl etc\n",
    "    text = format_func_names(text,func_dict,new_output_file_dir.split('-')[0]) \n",
    "    text = format_suffix_vars(text)\n",
    "    \n",
    "    text = format_values(text) \n",
    "    text = format_TAG(text,opcode_set,register_set,dummy_set)\n",
    "    text = replace_words(text,opcode_set,register_set,dummy_set)\n",
    "    text = formulate_sentence(text)\n",
    "    \n",
    "    #Write the cleaned text to the output file\n",
    "    with open(output_file_path, 'w') as file:\n",
    "         file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    ISA='mips32'\n",
    "    log_path = \"../original_dataset/gdl_pb_formatted/log\"\n",
    "    os.makedirs(log_path, exist_ok=True)\n",
    "    log_file = os.path.join(log_path, f\"{ISA}_formatting.log\")\n",
    "    logging.basicConfig(filename=log_file, level=logging.INFO, format='%(message)s')\n",
    "    \n",
    "    # Use glob to find all '.gdl' files recursively in the current folder and sub-folders\n",
    "    #input_path = glob.glob(f'../original_dataset/gdl_pb/{ISA}_malware/**/**/*.gdl', recursive=True)\n",
    "    input_path = glob.glob(f'../original_dataset/gdl_pb/{ISA}/**/**/*.gdl', recursive=True)\n",
    "    #print(input_path)\n",
    "    output_path=f\"../original_dataset/gdl_pb_formatted/{ISA}\"\n",
    "    #output_path=f\"../Malware_detection_files/param_study_arm64/tensors/{ISA}_unformatted/{ISA}_malware\"\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    opcode_set_path=f'../original_dataset/opcode_operand/{ISA}/opcode_counts.txt'\n",
    "    register_set_path=f'../original_dataset/opcode_operand/{ISA}/register_counts.txt'\n",
    "\n",
    "    zlib_func_set_path='../original_dataset/func_set/mips32_func_set/zlib-1.2.11-bin_func.txt'\n",
    "    binutils_func_set_path='../original_dataset/func_set/mips32_func_set/binutils-2.34-bin_func.txt'\n",
    "    coreutils_func_set_path='../original_dataset/func_set/mips32_func_set/coreutils-9.0-bin_func.txt'\n",
    "    curl_func_set_path='../original_dataset/func_set/mips32_func_set/curl-7.87-bin_func.txt'\n",
    "    diffutils_func_set_path='../original_dataset/func_set/mips32_func_set/diffutils-3.7-bin_func.txt'\n",
    "    findutils_func_set_path='../original_dataset/func_set/mips32_func_set/findutils-4.8.0-bin_func.txt'\n",
    "    libgpg_error_func_set_path='../original_dataset/func_set/mips32_func_set/libgpg-error-1.45-bin_func.txt'\n",
    "    openssl_func_set_path='../original_dataset/func_set/mips32_func_set/openssl-1.1.1p-bin_func.txt'\n",
    "\n",
    "    opcode_set=set()\n",
    "    register_set=set()\n",
    "    zlib_func_set=set()\n",
    "    binutils_func_set=set()\n",
    "    coreutils_func_set=set()\n",
    "    curl_func_set=set()\n",
    "    diffutils_func_set=set()\n",
    "    findutils_func_set=set()\n",
    "    libgpg_error_func_set=set()\n",
    "    openssl_func_set=set()\n",
    "\n",
    "    dummy_set={'TAG','VALUE','HEX','FUNC','STR','DWORD','JPT','ASC','UNK','TBYTE','QWORD','XMMWORD','LONG',\n",
    "               'DOUBLE','ARRAY','STRING','ARG','BYTE','SUB','WORD','LOCRET','DEF','OFF','FLT','DBL','LOC',\n",
    "               'STRU','GPGRT','GPG','YMMWORD','BUF','FILE','CALLBACK','CB','CURLSH','BUFFER','SCWTCH','VAR','STR',\n",
    "               'VAL','ALGN','SEG','SRC','INPUT','LOCAL','IMM','DUMMY','STD','ALLOC'}\n",
    "\n",
    "    with open(opcode_set_path,'r') as file: \n",
    "        for line in file: \n",
    "            opcode_set.add(line.split(' ')[0])\n",
    "\n",
    "    logging.info('The opcode set includes: ')\n",
    "    for item in opcode_set:\n",
    "        logging.info(f'{item} ')\n",
    "\n",
    "    with open(register_set_path,'r') as file:\n",
    "        for line in file:\n",
    "            register_set.add(line.split(' ')[0])\n",
    "\n",
    "    logging.info('The register set includes: ')\n",
    "    for item in register_set:\n",
    "        logging.info(f'{item} ')\n",
    "\n",
    "    with open(zlib_func_set_path,'r') as file:\n",
    "        for line in file:\n",
    "            zlib_func_set.add(line.strip())  \n",
    "\n",
    "    with open(binutils_func_set_path,'r') as file:\n",
    "        for line in file:\n",
    "            binutils_func_set.add(line.strip())   \n",
    "\n",
    "    with open(coreutils_func_set_path,'r') as file:\n",
    "        for line in file:\n",
    "            coreutils_func_set.add(line.strip())  \n",
    "\n",
    "    with open(curl_func_set_path,'r') as file:\n",
    "        for line in file:\n",
    "            curl_func_set.add(line.strip())  \n",
    "\n",
    "    with open(diffutils_func_set_path,'r') as file:\n",
    "        for line in file:\n",
    "            diffutils_func_set.add(line.strip())  \n",
    "\n",
    "    with open(findutils_func_set_path,'r') as file:\n",
    "        for line in file:\n",
    "            findutils_func_set.add(line.strip())  \n",
    "\n",
    "    with open(libgpg_error_func_set_path,'r') as file:\n",
    "        for line in file:\n",
    "            libgpg_error_func_set.add(line.strip())  \n",
    "\n",
    "    with open(openssl_func_set_path,'r') as file:\n",
    "        for line in file:\n",
    "            openssl_func_set.add(line.strip())        \n",
    "\n",
    "    func_dict={'zlib':zlib_func_set, 'binutils':binutils_func_set,'openssl':openssl_func_set, \n",
    "               'findutils':findutils_func_set,'diffutils':diffutils_func_set,'libgpg_error':libgpg_error_func_set,\n",
    "               'curl':curl_func_set,'coreutils':coreutils_func_set}\n",
    "\n",
    "    # Process each file\n",
    "    for gdl_file_path in input_path[:20]:\n",
    "        process_file(gdl_file_path, output_path,func_dict,opcode_set,register_set,dummy_set)\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
