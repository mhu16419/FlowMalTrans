{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob # folder operations\n",
    "import re # use regular expressions\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_func_names(text, func_dict,lib):\n",
    "\n",
    "    if lib=='binutils':\n",
    "        func_set=func_dict['binutils']\n",
    "    elif lib=='coreutils':\n",
    "        func_set=func_dict['coreutils']\n",
    "    elif lib=='curl':\n",
    "        func_set=func_dict['curl']\n",
    "    elif lib=='diffutils':\n",
    "        func_set=func_dict['diffutils']\n",
    "    elif lib=='findutils':\n",
    "        func_set=func_dict['findutils']\n",
    "    elif lib=='libgpg':\n",
    "        func_set=func_dict['libgpg_error']    \n",
    "    elif lib=='openssl':\n",
    "        func_set=func_dict['openssl']\n",
    "    elif lib=='zlib':\n",
    "        func_set=func_dict['zlib']\n",
    "    else: \n",
    "        func_set=set()\n",
    "        print(f\"Warning, undetected library: {lib}\")                        \n",
    "\n",
    "    pattern=r'\\b(' + '|'.join(func_set) + r')\\b'\n",
    "    # Split the text into lines\n",
    "    lines = text.split('\\n')\n",
    "    formatted_lines = []\n",
    "\n",
    "    # Iterate over each line\n",
    "    for line in lines:\n",
    "        # Split the line into the first word and the rest of the line\n",
    "        parts = line.split(' ', 1)\n",
    "        first_word = parts[0]\n",
    "        rest_of_line = parts[1] if len(parts) > 1 else ''\n",
    "\n",
    "        # Replace occurrences of any function name in the rest of the line with '<FUNC>'\n",
    "        modified_rest_of_line = re.sub(r'_\\b(' + '|'.join(func_set) + r')\\b', '<FUNC>', rest_of_line)\n",
    "        modified_rest_of_line = re.sub(pattern, '<FUNC>', rest_of_line)\n",
    "        #modified_rest_of_line = re.sub(underscore_pattern, '<FUNC>', modified_rest_of_line)\n",
    "        #print(pattern)\n",
    "        # Concatenate the first word and the modified rest of the line\n",
    "        formatted_line = first_word + (' ' + modified_rest_of_line if modified_rest_of_line else '')\n",
    "        formatted_lines.append(formatted_line)\n",
    "\n",
    "    # Join the formatted lines back into text\n",
    "    formatted_text = '\\n'.join(formatted_lines)\n",
    "    return formatted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_suffix_vars(text):\n",
    "    lines=text.split('\\n')\n",
    "    dash_var_pattern=re.compile(r'[0-9a-zA-Z_\\.]+([_|\\.]+[0-9a-zA-Z]+[_]*)+')\n",
    "    tag2_pattern=re.compile(r'(_[a-zA-Z0-9]+)|(([a-zA-Z0-9]+)_)')\n",
    "\n",
    "    aLarge_pattern=re.compile(r'(?<![a-zA-Z])a[A-Z][a-z0-9A-Z]+\\_*\\d*')# match anything except for a lower or upper case letter\n",
    "    dword_pattern=re.compile(r'(?<![a-zA-Z])dword_[0-9a-zA-Z_]+')\n",
    "    jpt_pattern=re.compile(r'(?<![a-zA-Z])jpt_[0-9a-zA-Z_]+')\n",
    "    asc_pattern=re.compile(r'(?<![a-zA-Z])asc_[0-9a-zA-Z_]+')\n",
    "    unk_pattern=re.compile(r'(?<![a-zA-Z])unk_[0-9a-zA-Z_]+')\n",
    "    tbyte_pattern=re.compile(r'(?<![a-zA-Z])tbyte_[0-9a-zA-Z_]+')\n",
    "    qword_pattern=re.compile(r'(?<![a-zA-Z])qword_[0-9a-zA-Z_]+')\n",
    "    xmmword_pattern=re.compile(r'(?<![a-zA-Z])xmmword_[0-9a-zA-Z_]+')\n",
    "    long_pattern=re.compile(r'(?<![a-zA-Z])long_[0-9a-zA-Z_]+')\n",
    "    double_pattern=re.compile(r'(?<![a-zA-Z])double_[0-9a-zA-Z_]+')\n",
    "    array_pattern=re.compile(r'(?<![a-zA-Z])array_[0-9a-zA-Z_]+')\n",
    "    string_pattern=re.compile(r'(?<![a-zA-Z])string_[0-9a-zA-Z_]+')\n",
    "    arg_pattern=re.compile(r'(?<![a-zA-Z])arg_[0-9a-zA-Z_]+')\n",
    "    byte_pattern=re.compile(r'(?<![a-zA-Z])byte_[0-9a-zA-Z_]+')\n",
    "    sub_pattern=re.compile(r'(?<![a-zA-Z])sub_[0-9a-zA-Z_]+')\n",
    "    word_pattern=re.compile(r'(?<![a-zA-Z])word_[0-9a-zA-Z_]+')\n",
    "    locret_pattern=re.compile(r'(?<![a-zA-Z])locret_[0-9a-zA-Z_]+')\n",
    "    def_pattern=re.compile(r'(?<![a-zA-Z])def_[0-9a-zA-Z_]+')\n",
    "    off_pattern=re.compile(r'(?<![a-zA-Z])off_[0-9a-zA-Z_]+')\n",
    "    flt_pattern=re.compile(r'(?<![a-zA-Z])flt_[0-9a-zA-Z_]+')\n",
    "    dbl_pattern=re.compile(r'(?<![a-zA-Z])dbl_[0-9a-zA-Z_]+')\n",
    "    loc_pattern=re.compile(r'(?<![a-zA-Z])loc_[0-9a-zA-Z_]+')\n",
    "    stru_pattern=re.compile(r'(?<![a-zA-Z])stru_[0-9a-zA-Z_]+')\n",
    "    gpgrt_pattern=re.compile(r'(?<![a-zA-Z])gpgrt_[0-9a-zA-Z_]+')\n",
    "    gpg_pattern=re.compile(r'(?<![a-zA-Z])gpg_[0-9a-zA-Z_]+')\n",
    "    ymmword_pattern=re.compile(r'(?<![a-zA-Z])ymmword_[0-9a-zA-Z_]+')\n",
    "    buf_pattern=re.compile(r'(?<![a-zA-Z])buf_[0-9a-zA-Z_]+')\n",
    "    FILE_pattern=re.compile(r'(?<![a-zA-Z])FILE_[0-9a-zA-Z_]+')\n",
    "    callback_pattern=re.compile(r'(?<![a-zA-Z])callback_[0-9a-zA-Z_]+')\n",
    "    cb_pattern=re.compile(r'(?<![a-zA-Z])cb_[0-9a-zA-Z_]+')\n",
    "    CURLSH_pattern=re.compile(r'(?<![a-zA-Z])CURLSH_[0-9a-zA-Z_]+')\n",
    "    buffer_pattern=re.compile(r'(?<![a-zA-Z])buffer_[0-9a-zA-Z_]+')\n",
    "    CSWTCH_pattern=re.compile(r'(?<![a-zA-Z])CSWTCH_[0-9a-zA-Z_]+')\n",
    "    var_pattern=re.compile(r'(?<![a-zA-Z])var_[0-9a-zA-Z_]+')\n",
    "    str_pattern=re.compile(r'(?<![a-zA-Z])str_[0-9a-zA-Z_]+')\n",
    "    val_pattern=re.compile(r'(?<![a-zA-Z])val_[0-9a-zA-Z_]+')\n",
    "    pretty_function_pattern=re.compile(r'(?<![a-zA-Z])__PRETTY_FUNCTION___\\d+')\n",
    "    algn_pattern=re.compile(r'(?<![a-zA-Z])algn_[0-9a-zA-Z_]+')\n",
    "    seg_pattern=re.compile(r'(?<![a-zA-Z])seg_[0-9a-zA-Z_]+')\n",
    "    src_pattern=re.compile(r'(?<![a-zA-Z])src_[0-9a-zA-Z_]+')\n",
    "    input_pattern=re.compile(r'(?<![a-zA-Z])input_[0-9a-zA-Z_]+')\n",
    "    local_pattern=re.compile(r'(?<![a-zA-Z])local_[0-9a-zA-Z_]+')\n",
    "    imm_pattern=re.compile(r'([\\s#\\.])imm[0-9a-zA-Z_]+')\n",
    "    dummy_pattern=re.compile(r'([\\s#\\.])dummy[0-9a-zA-Z__]*')\n",
    "    std_pattern=re.compile(r'([\\s#\\.])std_[0-9a-zA-Z_]+')\n",
    "    alloc_pattern=re.compile(r'(?<![a-zA-Z])alloc_[0-9a-zA-Z_]+')\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    formatted_lines=[]\n",
    "    for line in lines:\n",
    "\n",
    "        line=dash_var_pattern.sub(\"<TAG>\",line)\n",
    "        line=tag2_pattern.sub(\"<TAG>\",line)\n",
    "\n",
    "        line=aLarge_pattern.sub('<STR>',line)\n",
    "        line=dword_pattern.sub('<DWORD>',line)\n",
    "        line=jpt_pattern.sub('<JPT>',line)\n",
    "        line=asc_pattern.sub('<ASC>',line)\n",
    "        line=unk_pattern.sub('<UNK>',line)\n",
    "        line=tbyte_pattern.sub('<TBYTE>',line)\n",
    "        line=qword_pattern.sub('<QWORD>',line)\n",
    "        line=xmmword_pattern.sub('<XMMWORD>',line)\n",
    "        line=long_pattern.sub('<LONG>',line)\n",
    "        line=double_pattern.sub('<DOUBLE>',line)\n",
    "        line=array_pattern.sub('<ARRAY>',line)\n",
    "        line=string_pattern.sub('<STRING>',line)\n",
    "        line=arg_pattern.sub('<ARG>',line)\n",
    "        line=byte_pattern.sub('<BYTE>',line)\n",
    "        line=sub_pattern.sub('<SUB>',line)\n",
    "        line=word_pattern.sub('<WORD>',line)\n",
    "        line=locret_pattern.sub('<LOCRET>',line)\n",
    "        line=def_pattern.sub('<DEF>',line)\n",
    "        line=off_pattern.sub('<OFF>',line)\n",
    "        line=flt_pattern.sub('<FLT>',line)\n",
    "        line=dbl_pattern.sub('<DBL>',line)\n",
    "        line=loc_pattern.sub('<LOC>',line)\n",
    "        line=stru_pattern.sub('<STRU>',line)\n",
    "        line=gpgrt_pattern.sub('<GPGRT>',line)\n",
    "        line=gpg_pattern.sub('<GPG>',line)\n",
    "        line=ymmword_pattern.sub('<YMMWORD>',line)\n",
    "        line=buf_pattern.sub('<BUF>',line)\n",
    "        line=FILE_pattern.sub('<FILE>',line)\n",
    "        line=callback_pattern.sub('<CALLBACK>',line)\n",
    "        line=cb_pattern.sub('<CB>',line)\n",
    "        line=CURLSH_pattern.sub('<CURLSH>',line)\n",
    "        line=buffer_pattern.sub('<BUFFER>',line)\n",
    "        line=CSWTCH_pattern.sub('<SCWTCH>',line)\n",
    "        line=var_pattern.sub('<VAR>',line)\n",
    "        line=str_pattern.sub('<STR>',line)\n",
    "        line=val_pattern.sub('<VAL>',line)\n",
    "        line=pretty_function_pattern.sub('<FUNC>',line)\n",
    "        line=algn_pattern.sub(\"<ALGN>\",line)\n",
    "        line=seg_pattern.sub(\"<SEG>\",line)\n",
    "        line=src_pattern.sub(\"<SRC>\",line)\n",
    "        line=input_pattern.sub(\"<INPUT>\",line)\n",
    "        line=local_pattern.sub(\"<LOCAL>\",line)\n",
    "        line=imm_pattern.sub(\"<IMM>\",line)\n",
    "        line=dummy_pattern.sub(\"<DUMMY>\",line)\n",
    "        line=std_pattern.sub(\"<STD>\",line)\n",
    "        line=alloc_pattern.sub(\"<ALLOC>\",line)\n",
    "        \n",
    "\n",
    "        formatted_lines.append(line)\n",
    "    formatted_text='\\n'.join(formatted_lines)    \n",
    "    return formatted_text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_call_func(text):\n",
    "    \"\"\"\n",
    "    Converts lines starting with 'call' to '<FUNC_CALL>'.\n",
    "\n",
    "    Parameters:\n",
    "    - text (str): The input text in which to convert the lines.\n",
    "\n",
    "    Return\n",
    "    - str: The text with 'call' lines converted.The exact function is replaced with '<FUNC>'\n",
    "    \"\"\"\n",
    "    # Split the text into lines\n",
    "    lines = text.split('\\n')\n",
    "    # Convert lines starting with 'call'\n",
    "    converted_lines = ['call <FUNC>' if line.lstrip().startswith('call') else line for line in lines]\n",
    "    # Join the lines back into a single string\n",
    "    return '\\n'.join(converted_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_values(text):\n",
    "    \"\"\"\n",
    "    It identifies the hex value with '0x' prefix. If the digits exceeds 4, replace it\n",
    "    with '0x_VALUE', otherwise keep it. \n",
    "    \"\"\"\n",
    "    hex_pattern1 = re.compile(r'0x[a-fA-F0-9]+')# regular expression for hex value\n",
    "                                                  # more than 4 digits\n",
    "    hex_pattern2 = re.compile(r'(?<![a-zA-Z])[a-fA-F0-9]+h')   \n",
    "    decimal_pattern=re.compile(r'(?<![a-zA-Z])\\d+')                                           \n",
    "    lines = text.split('\\n') # Split the text into lines\n",
    "    converted_lines = []\n",
    "    for line in lines:\n",
    "        line = hex_pattern1.sub('<HEX>', line)  # Apply the first pattern\n",
    "        line = re.sub(hex_pattern2,'<HEX>',line)  # Apply the second pattern\n",
    "        line = re.sub(decimal_pattern,'<VALUE>',line)\n",
    "        converted_lines.append(line)\n",
    "    #it replaces all the patterns with 'hex_VALUE' in the line\n",
    "    # Return the processed text\n",
    "    return '\\n'.join(converted_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_comments(text):\n",
    "    \"\"\"\n",
    "    Removes comments that appear after \"//\" and ';' in each line.\n",
    "\n",
    "    Parameters:\n",
    "    - text (str): The input text from which to remove the comments.\n",
    "\n",
    "    Returns:\n",
    "    - str: The text with comments removed.\n",
    "    \"\"\"\n",
    "    # Split the text into lines\n",
    "    lines = text.split('\\n')\n",
    "    # Remove comments from each line\n",
    "    cleaned_lines = [line.split('//')[0].rstrip() for line in lines]\n",
    "    cleaned_lines2=[line.split(';')[0].rstrip() for line in cleaned_lines]\n",
    "    cleaned_lines3=[line.split('\"')[0].rstrip() for line in cleaned_lines2]# the content after '\"' should also be deleted. \n",
    "    cleaned_lines4 = [line.split('node')[0] + 'node' if 'node' in line else line for line in cleaned_lines3]\n",
    "    cleaned_lines5=[line.split('extrn')[0].rstrip() for line in cleaned_lines4]\n",
    "    cleaned_lines6=[line.split('endbr')[0].rstrip() for line in cleaned_lines5]\n",
    "    # Join the lines back into a single string\n",
    "    return '\\n'.join(cleaned_lines6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_extra_lines(text):\n",
    "    \"\"\"\n",
    "    Removes lines that contain 'colorentry' and the numbers that follow.\n",
    "    We also remove the lines that start with 'edge:'. \n",
    "    We don't need those information. \n",
    "\n",
    "    Parameters:\n",
    "    - text (str): The input text from which to remove the lines.\n",
    "\n",
    "    Returns:\n",
    "    - str: The text with 'colorentry' lines removed.\n",
    "    \"\"\"\n",
    "    # Split the text into lines\n",
    "    lines = text.split('\\n')\n",
    "    # Remove lines containing 'colorentry'\n",
    "    lines=lines[10:]\n",
    "    cleaned_lines = [line for line in lines if not line.startswith('colorentry')\n",
    "                     |line.startswith('edge')|line.startswith('}')]\n",
    "    # Join the lines back into a single string\n",
    "    return '\\n'.join(cleaned_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_empty_lines(text):\n",
    "    '''\n",
    "    This function is used to delete empty lines in the formatted gdl file. \n",
    "    It also removed the fode information\n",
    "    '''\n",
    "    lines=text.split('\\n')\n",
    "    new_lines=[line for line in lines if line.strip()!='']\n",
    "    cleaned_text='\\n'.join(new_lines)\n",
    "    return cleaned_text  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formulate_sentence(text):\n",
    "    #this function formulates all the instructions within one node to a whole sentence. \n",
    "    #it also deletes all the commas in the text \n",
    "    lines=text.split('\\n')\n",
    "    output=''\n",
    "    current_line=''\n",
    "    for line in lines:\n",
    "        if line.strip()=='node':\n",
    "            if current_line:\n",
    "                output+=current_line.strip().replace(\",\", \"\")+'\\n'\n",
    "                current_line=\"\"\n",
    "        else:\n",
    "            current_line+=line.strip().replace(\",\", \"\")+' <E> '\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(gdl_file_path, output_path, func_dict):\n",
    "    \"\"\"\n",
    "    Reads a GDL file, applies cleaning functions, and writes the output to a new file.\n",
    "\n",
    "    Parameters:\n",
    "    - gdl_file_path (str): The path to the GDL file to be processed.\n",
    "    \"\"\"\n",
    "    # Extract the directory and the base name of the gdl file\n",
    "    file_dir, base_name = os.path.split(gdl_file_path)\n",
    "    #print(f\"the file directory is {file_dir}\")\n",
    "    #output_file_dir=file_dir.split('/')[-1]\n",
    "\n",
    "    \n",
    "    #The following command is to remove the version information so the comparison is easier\n",
    "    new_output_file_dir=(file_dir.split('-')[0]+'-'+file_dir.split('-')[-1]).split('/')[-1]\n",
    "    #print(f\"the new output file directory is {new_output_file_dir}\")\n",
    "    #print(f\"the output file directory is {output_file_dir}\")\n",
    "    # Remove the '.gdl' extension and add '_postprocessed'\n",
    "    output_base_name = base_name[:-4]\n",
    "    #output_file_path = os.path.join(file_dir, output_base_name)\n",
    "    #print(f\"the output file path is {output_base_name}\")  \n",
    "    output_name=new_output_file_dir+'-'+output_base_name\n",
    "    #print(f\"the output name is {output_name}\")\n",
    "    output_file_path=os.path.join(output_path,output_name)\n",
    "    # Read the input GDL file\n",
    "    with open(gdl_file_path, 'r') as file:\n",
    "         text = file.read()\n",
    "\n",
    "    text = remove_extra_lines(text)\n",
    "    text = remove_comments(text)\n",
    "    text = remove_empty_lines(text)\n",
    "    #text = format_call_func(text)\n",
    "    text = format_values(text)\n",
    "\n",
    "    # the last parameter corresponds to the lib: findutils, libgpg, openssl etc\n",
    "    #text = format_func_names(text,func_dict,new_output_file_dir.split('-')[0]) \n",
    "    text = format_suffix_vars(text) \n",
    "    \n",
    "    text = formulate_sentence(text)\n",
    "    \n",
    "    #Write the cleaned text to the output file\n",
    "    with open(output_file_path, 'w') as file:\n",
    "         file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    ISA='x86'\n",
    "    # Use glob to find all '.gdl' files recursively in the current folder and sub-folders\n",
    "    input_path = glob.glob(f'../original_dataset/gdl_pb/{ISA}/**/**/*.gdl', recursive=True)\n",
    "    #print(input_path)\n",
    "    output_path=f\"../original_dataset/gdl_pb_formatted/{ISA}\"\n",
    "    #output_path=f\"../Malware_detection_files/param_study_arm64/tensors/{ISA}_unformatted/{ISA}_malware\"\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    zlib_func_set_path='../original_dataset/func_set/x86_func_set/zlib-1.2.11-bin_func.txt'\n",
    "    binutils_func_set_path='../original_dataset/func_set/x86_func_set/binutils-2.34-bin_func.txt'\n",
    "    coreutils_func_set_path='../original_dataset/func_set/x86_func_set/coreutils-9.0-bin_func.txt'\n",
    "    curl_func_set_path='../original_dataset/func_set/x86_func_set/curl-7.87-bin_func.txt'\n",
    "    diffutils_func_set_path='../original_dataset/func_set/x86_func_set/diffutils-3.7-bin_func.txt'\n",
    "    findutils_func_set_path='../original_dataset/func_set/x86_func_set/findutils-4.8.0-bin_func.txt'\n",
    "    libgpg_error_func_set_path='../original_dataset/func_set/x86_func_set/libgpg-error-1.45-bin_func.txt'\n",
    "    openssl_func_set_path='../original_dataset/func_set/x86_func_set/openssl-1.1.1p-bin_func.txt'\n",
    "\n",
    "    zlib_func_set=set()\n",
    "    binutils_func_set=set()\n",
    "    coreutils_func_set=set()\n",
    "    curl_func_set=set()\n",
    "    diffutils_func_set=set()\n",
    "    findutils_func_set=set()\n",
    "    libgpg_error_func_set=set()\n",
    "    openssl_func_set=set()\n",
    "\n",
    "\n",
    "    with open(zlib_func_set_path,'r') as file:\n",
    "        for line in file:\n",
    "            zlib_func_set.add(line.strip())  \n",
    "\n",
    "    with open(binutils_func_set_path,'r') as file:\n",
    "        for line in file:\n",
    "            binutils_func_set.add(line.strip())   \n",
    "\n",
    "    with open(coreutils_func_set_path,'r') as file:\n",
    "        for line in file:\n",
    "            coreutils_func_set.add(line.strip())  \n",
    "\n",
    "    with open(curl_func_set_path,'r') as file:\n",
    "        for line in file:\n",
    "            curl_func_set.add(line.strip())  \n",
    "\n",
    "    with open(diffutils_func_set_path,'r') as file:\n",
    "        for line in file:\n",
    "            diffutils_func_set.add(line.strip())  \n",
    "\n",
    "    with open(findutils_func_set_path,'r') as file:\n",
    "        for line in file:\n",
    "            findutils_func_set.add(line.strip())  \n",
    "\n",
    "    with open(libgpg_error_func_set_path,'r') as file:\n",
    "        for line in file:\n",
    "            libgpg_error_func_set.add(line.strip())  \n",
    "\n",
    "    with open(openssl_func_set_path,'r') as file:\n",
    "        for line in file:\n",
    "            openssl_func_set.add(line.strip())        \n",
    "\n",
    "    func_dict={'zlib':zlib_func_set, 'binutils':binutils_func_set,'openssl':openssl_func_set, \n",
    "               'findutils':findutils_func_set,'diffutils':diffutils_func_set,'libgpg_error':libgpg_error_func_set,\n",
    "               'curl':curl_func_set,'coreutils':coreutils_func_set}\n",
    "\n",
    "    # Process each file\n",
    "    for gdl_file_path in input_path[:5]:\n",
    "        process_file(gdl_file_path, output_path,func_dict)\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
