{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from nltk import ngrams\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARM_translated_BB_Folder_Path = 'data/parallel_dataset_evaluation/arm32-x86/translated_x86-coreutils'\n",
    "x86_original_BB_Folder_Path = 'data/parallel_dataset_evaluation/arm32-x86/x86-coreutils'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_ref_length(translation_u, list_of_reference_u):\n",
    "    \"\"\"\n",
    "    determine the closest reference length from translation length\n",
    "    \"\"\"\n",
    "    len_trans = len(translation_u)\n",
    "    closest_ref_idx = np.argmin([abs(len(x) - len_trans) for x in list_of_reference_u])\n",
    "    return len(list_of_reference_u[closest_ref_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brevity_penalty(translation_u, list_of_reference_u):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    c = len(translation_u)\n",
    "    r = closest_ref_length(translation_u, list_of_reference_u)\n",
    "\n",
    "    if c > r:\n",
    "        return 1\n",
    "    else:\n",
    "        return np.exp(1 - float(r) / c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_ngram(unigram, ngram=1):\n",
    "    \"\"\"\n",
    "    Return\n",
    "    -----\n",
    "    counter: dict, containing ngram as key, and count as value\n",
    "    \"\"\"\n",
    "    return Counter(ngrams(unigram, ngram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_clip_ngram(translation_u, list_of_reference_u, ngram=1):\n",
    "    \n",
    "    \"\"\"\n",
    "    Return\n",
    "   clipped counts of the ngram for candidate and reference translation\n",
    "\n",
    "    \"\"\"\n",
    "    res = dict()\n",
    "    # retrieve hypothesis counts\n",
    "    ct_translation_u = count_ngram(translation_u, ngram=ngram)\n",
    "\n",
    "    # retrieve translation candidate counts\n",
    "    for reference_u in list_of_reference_u:\n",
    "        ct_reference_u = count_ngram(reference_u, ngram=ngram)\n",
    "        for k in ct_reference_u:\n",
    "            if k in res:\n",
    "                res[k] = max(ct_reference_u[k], res[k])\n",
    "            else:\n",
    "                res[k] = ct_reference_u[k]\n",
    "\n",
    "    return {\n",
    "        k: min(ct_translation_u.get(k, 0), res.get(k, 0))\n",
    "        for k in ct_translation_u\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_ngram(unigram, ngram=1):\n",
    "    \"\"\"\n",
    "    Return\n",
    "    -----\n",
    "    counter: dict, containing ngram as key, and count as value\n",
    "    \"\"\"\n",
    "    return Counter(ngrams(unigram, ngram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modified_precision(translation, list_of_references, ngram=1):\n",
    "    \"\"\"\n",
    "    Return\n",
    "    modified precision = clipped counts/ no. of unclipped candidate n-gram\n",
    "\n",
    "    \"\"\"\n",
    "    ct_clip = count_clip_ngram(translation, list_of_references, ngram)\n",
    "    ct = count_ngram(translation, ngram)\n",
    "\n",
    "    return sum(ct_clip.values()) / float(max(sum(ct.values()), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu_score(translation_u, list_of_reference_u, W=[0.25 for x in range(4)]):\n",
    "    bp = brevity_penalty(translation_u, list_of_reference_u)\n",
    "    modified_precisions = [\n",
    "        modified_precision(translation_u, list_of_reference_u, ngram=ngram)\n",
    "        for ngram, _ in enumerate(W, start=1)\n",
    "    ]\n",
    "    score = np.sum([\n",
    "        wn * np.log(modified_precisions[i]) if modified_precisions[i] != 0 else 0 for i, wn in enumerate(W)\n",
    "    ])\n",
    "\n",
    "    return bp * np.exp(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "\ttotal_BLEU = 0\n",
    "\ttotal_lines = 0\n",
    "\ttotal_GDL_with_diff_line_count = 0\n",
    "\tfiles = os.listdir(ARM_translated_BB_Folder_Path)\n",
    "\tno_of_files = len(files)\n",
    "\tfor arm_file in files:\n",
    "\t\t# print('arm_file = ', arm_file)\n",
    "\t\tarm_full_path = os.path.join(ARM_translated_BB_Folder_Path, arm_file)\n",
    "\t\tx86_file_full_path = os.path.join(x86_original_BB_Folder_Path, arm_file)\n",
    "\t\t# arm_file_parts = arm_file.split('-ARM-')\n",
    "\t\t# x86_GDL_file_name = arm_file_parts[0] + '-' + arm_file_parts[1]\n",
    "\t\t# x86_file_full_path = os.path.join(x86_original_BB_Folder_Path, x86_GDL_file_name)\n",
    "\n",
    "\t\twith open(arm_full_path, \"r\", errors='ignore') as fp_arm_in, open(x86_file_full_path, \"r\",\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\terrors='ignore') as fp_x86_in:\n",
    "\t\t\tprint('arm_file = ', arm_file)\n",
    "\t\t\treference_x86_instrs = []\n",
    "\t\t\ttranslated_x86_instrs = []\n",
    "\t\t\tfor gdl_line in fp_x86_in:\n",
    "\t\t\t\tif len(gdl_line.strip()) == 0:\n",
    "\t\t\t\t\tgdl_line = \"MISNULL\"\n",
    "\t\t\t\treference_x86_instrs.append(gdl_line.strip())\n",
    "\n",
    "\t\t\tfor gdl_line in fp_arm_in:\n",
    "\t\t\t\tif len(gdl_line.strip()) == 0:\n",
    "\t\t\t\t\tgdl_line = \"MISNULL\"\n",
    "\t\t\t\ttranslated_x86_instrs.append(gdl_line.strip())\n",
    "\n",
    "\t\t\tif not len(reference_x86_instrs) == len(translated_x86_instrs):\n",
    "\t\t\t\tno_of_line_difference = max(len(reference_x86_instrs),len(translated_x86_instrs)) - min(len(reference_x86_instrs),len(translated_x86_instrs))\n",
    "\t\t\t\ttotal_GDL_with_diff_line_count+=1\n",
    "\n",
    "\t\t\t\tif len(reference_x86_instrs) < len(translated_x86_instrs):\n",
    "\t\t\t\t\tfor i in range(no_of_line_difference):\n",
    "\t\t\t\t\t\treference_x86_instrs.append(\"LENDIF\")\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tfor i in range(no_of_line_difference):\n",
    "\t\t\t\t\t\ttranslated_x86_instrs.append(\"LENDIF\")\n",
    "\n",
    "\t\t\t# print(\"BLEU\", bleu_score(translation, list_of_references))\n",
    "\t\t\tprint('reference_x86_instrs = ', reference_x86_instrs)\n",
    "\t\t\tprint('translated_x86_instrs = ', translated_x86_instrs)\n",
    "\t\t\tfor i in range(min(len(reference_x86_instrs),len(translated_x86_instrs))):#may need to change to max\n",
    "\t\t\t\tbleu_score_val = bleu_score(translated_x86_instrs[i], reference_x86_instrs[i])\n",
    "\t\t\t\tprint('i = ', i, ' bleu_score_val = ', bleu_score_val)\n",
    "\t\t\t\ttotal_BLEU = total_BLEU + bleu_score_val\n",
    "\t\t\t\ttotal_lines = total_lines + 1\n",
    "\n",
    "\t\t\t# bleu_score_val = bleu_score(translated_x86_instrs, reference_x86_instrs)\n",
    "\t\t\t# print('bleu_score_val = ', bleu_score_val)\n",
    "\t\t\t# total_BLEU = total_BLEU + bleu_score_val\n",
    "\n",
    "\t# end of reading files and generating 2 arrays of texts\n",
    "\n",
    "\t# # print(\"BLEU\", bleu_score(translation, list_of_references))\n",
    "\t# bleu_score_val = bleu_score(translated_x86_instrs, reference_x86_instrs) #\n",
    "\tprint('average BLEU for ', total_lines, ' lines is = ', total_BLEU / total_lines)\n",
    "\t# print('average BLEU for ', total_lines, ' lines is = ', total_BLEU / max(len(reference_x86_instrs),len(translated_x86_instrs)))\n",
    "\tprint('total_GDL_with_diff_line_count = ', total_GDL_with_diff_line_count)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\tmain()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
